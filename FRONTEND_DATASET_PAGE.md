# New Dataset Detail Page âœ¨

## What's New?

I've created a **complete dataset detail page** where you can:
- âœ… View dataset information
- âœ… Click "Start Analysis" to trigger anomaly detection
- âœ… See real-time progress
- âœ… View detected anomalies in a table
- âœ… Filter and sort results

---

## ðŸŽ¯ How to Use

### Step 1: Upload a Dataset

1. Go to `http://localhost:3000`
2. Login
3. Upload your `.xlsx` or `.csv` file

### Step 2: View Dataset & Start Analysis

1. After upload, you'll see your dataset in the list
2. Click the **"Analyze"** button (for pending datasets)
   - Or click **"View Details"** (for already analyzed datasets)

3. You'll be taken to the **Dataset Detail Page**

### Step 3: Trigger Analysis

On the detail page:

1. You'll see dataset info:
   - File size
   - Upload date
   - Status
   - S3 storage location

2. Click the **"Start Analysis"** button

3. Watch the progress bar (30-90 seconds for small datasets)

4. Once complete, anomalies appear in a table!

### Step 4: Review Anomalies

The anomalies table shows:
- **Row Index** - Which row in your dataset
- **Anomaly Score** - How unusual (higher = more anomalous)
  - ðŸ”´ Red tag: High score (>0.2)
  - ðŸŸ  Orange tag: Medium score (>0.1)
  - ðŸŸ¡ Gold tag: Low score
- **Suspicious Features** - Top 3 features that are unusual
- **Status** - Detected, Investigating, Resolved, etc.
- **Detected At** - Timestamp

---

## ðŸ“¸ Page Features

### Dataset Info Card
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ File Size      â”‚ Anomalies â”‚ Uploaded  â”‚ Status â”‚
â”‚ 45.2 KB        â”‚ 52        â”‚ Nov 6     â”‚ âœ“ Done â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Original Filename: beth_sample_5k.csv           â”‚
â”‚ Content Type: text/csv                          â”‚
â”‚ S3 Key: datasets/user_id/filename.csv          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Analysis Button (for pending datasets)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â„¹ï¸ Dataset not analyzed yet                     â”‚
â”‚                                                  â”‚
â”‚ Click the button below to start anomaly         â”‚
â”‚ detection analysis.                              â”‚
â”‚                                  [ðŸš€ Start Analysis]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Progress Indicator (during analysis)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyzing dataset...                            â”‚
â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘ 75%                       â”‚
â”‚ This may take a few minutes.                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Anomalies Table
```
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Row â”‚ Score     â”‚ Suspicious Features            â”‚ Status     â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 42 â”‚ðŸ”´ 0.2456  â”‚ request_count: 1567 (0.823)    â”‚ðŸŸ  Detected â”‚
â”‚    â”‚           â”‚ response_time_ms: 12345 (0.612)â”‚            â”‚
â”‚ 89 â”‚ðŸ”´ 0.1892  â”‚ data_transfer_mb: 2500 (0.934) â”‚ðŸŸ  Detected â”‚
â”‚156 â”‚ðŸŸ  0.1234  â”‚ failed_logins: 45 (0.456)      â”‚ðŸŸ  Detected â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” Understanding the Anomaly Table

### Anomaly Score
- Measures how much the autoencoder struggled to reconstruct that row
- **Higher score = More anomalous**
- Color coding:
  - ðŸ”´ **Red (>0.2):** High priority - very unusual
  - ðŸŸ  **Orange (>0.1):** Medium priority - somewhat unusual
  - ðŸŸ¡ **Gold (<0.1):** Low priority - slightly unusual

### Suspicious Features
Shows the top 3 features that contributed to the anomaly:

**Format:** `feature_name: actual_value (reconstruction_error)`

**Example:**
```
request_count: 1567 (error: 0.823)
  â†‘              â†‘          â†‘
  Feature     Actual    How badly it
  name        value     failed to reconstruct
```

**What it means:**
- The autoencoder expected `request_count` to be ~15-20
- But it found `1567` (way higher!)
- Reconstruction error of `0.823` means it's VERY unusual

---

## ðŸŽ¨ Status Colors

Datasets have status colors:
- ðŸŸ¢ **Green (Completed):** Analysis done, view anomalies
- ðŸ”µ **Blue (Processing):** Currently analyzing
- ðŸŸ  **Orange (Pending):** Not analyzed yet, click "Analyze"
- ðŸ”´ **Red (Failed):** Analysis error, try again

Anomalies have status tags:
- ðŸŸ  **Detected:** Newly found, not reviewed
- ðŸ”µ **Investigating:** Being looked at
- ðŸŸ¢ **Resolved:** Confirmed anomaly, handled
- âšª **False Positive:** Not actually an issue

---

## ðŸš€ Quick Demo Flow

```bash
# 1. Generate test data
python3 generate_test_data.py

# 2. Open browser
open http://localhost:3000

# 3. Login (admin / password123)

# 4. Upload test_dataset_with_anomalies.xlsx
#    - Drag & drop the file

# 5. Click "Analyze" button

# 6. Wait ~30 seconds

# 7. See the results!
#    - 50 anomalies detected
#    - DDoS attacks (high request_count)
#    - Data exfiltration (huge data_transfer_mb)
#    - Brute force (many failed_logins)
```

---

## ðŸ”§ Technical Details

### Navigation Flow
```
HomePage â†’ Upload file â†’ Dataset appears in list
         â†“
   Click "Analyze" button
         â†“
DatasetDetailPage â†’ Show dataset info
         â†“
   Click "Start Analysis"
         â†“
   POST /api/anomaly/datasets/{id}/analyze-test
         â†“
   Progress indicator (simulated)
         â†“
   Anomalies table auto-refreshes
```

### API Calls Made
1. **GET** `/api/anomaly/datasets/{id}` - Fetch dataset info
2. **GET** `/api/anomaly/datasets/{id}/anomalies` - Fetch anomalies
3. **POST** `/api/anomaly/datasets/{id}/analyze-test` - Trigger analysis

### Files Created
```
frontend/src/pages/
â”œâ”€â”€ DatasetDetail/
â”‚   â”œâ”€â”€ DatasetDetailPage.jsx  â† New page component
â”‚   â””â”€â”€ index.js               â† Export

frontend/src/pages/layout/main/
â””â”€â”€ MainLayout.jsx             â† Updated routing

frontend/src/pages/HomePage/
â””â”€â”€ HomePage.jsx               â† Updated navigation
```

---

## ðŸŽ¯ What Happens During Analysis?

```
1. User clicks "Start Analysis"
   â†“
2. Frontend sends POST request
   â†“
3. Backend downloads Excel/CSV from S3
   â†“
4. Parses data with pandas
   â†“
5. Trains autoencoder on data (30-90 sec)
   â”‚  â”œâ”€ Input layer (n features)
   â”‚  â”œâ”€ Encoder (compress to 8 dims)
   â”‚  â”œâ”€ Decoder (reconstruct back)
   â”‚  â””â”€ Learn normal patterns
   â†“
6. Calculate reconstruction errors per row
   â†“
7. Flag top 5% (95th percentile) as anomalies
   â†“
8. Store in MongoDB with features
   â†“
9. Frontend shows results in table!
```

---

## âœ¨ Features & Interactions

### Sorting
- Click column headers to sort
- Default: sorted by anomaly score (highest first)

### Pagination
- 10 rows per page (configurable)
- "Show total" at bottom
- Page size changer (10, 20, 50, 100)

### Actions
- **Refresh button** - Reload anomalies from server
- **Export button** - (Coming soon) Export to CSV/PDF
- **Back button** - Return to home page

### Responsive
- Works on desktop, tablet, mobile
- Table scrolls horizontally on small screens
- Cards stack vertically on mobile

---

## ðŸ› Troubleshooting

### "Dataset not found"
- **Cause:** Invalid dataset ID in URL
- **Fix:** Go back to home page and try again

### "Analysis failed"
- **Cause:** TensorFlow not installed or data parsing error
- **Fix:** Check backend logs: `docker-compose logs backend --tail 50`

### "No anomalies detected"
- **Cause:** Data is too uniform OR threshold too high
- **Fix:** Try with more diverse data or regenerate test data

### Analysis takes too long (>2 min)
- **Cause:** Large dataset (>50K rows)
- **Fix:** Normal! For production, use async Celery tasks

### Progress bar stuck at 90%
- **Cause:** Still training (progress is simulated)
- **Fix:** Wait for it to complete (check backend logs)

---

## ðŸ“Š Example Results

### After analyzing `test_dataset_with_anomalies.xlsx`:

**Dataset Info:**
- Total rows: 550
- Anomalies detected: 52 (9.45%)
- Analysis time: ~45 seconds

**Top 3 Anomalies:**

1. **Row 42** - Score: 0.2456
   - `request_count`: 1567 (expected ~15)
   - `response_time_ms`: 12345 (expected ~100)
   - **Type:** DDoS attack

2. **Row 89** - Score: 0.1892
   - `data_transfer_mb`: 2500 (expected ~50)
   - `port`: 9999 (expected 80/443)
   - **Type:** Data exfiltration

3. **Row 156** - Score: 0.1234
   - `failed_logins`: 45 (expected <1)
   - `status_code`: 401
   - **Type:** Brute force attack

---

## ðŸŽ‰ You're All Set!

The frontend is now complete with:
âœ… Upload page
âœ… Dataset list
âœ… Detail page with analysis button
âœ… Real-time progress indicator
âœ… Anomalies table with sorting/filtering
âœ… Responsive design

**Try it now:**
```
http://localhost:3000
```

Upload a file â†’ Click "Analyze" â†’ Watch the magic happen! âœ¨
